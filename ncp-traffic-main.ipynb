{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "COMPSCI 760 Group Project :Extending NCP to supervised learning - traffic dataset \n",
    "Found at https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
    "Original NCP repo :https://github.com/mlech26l/keras-ncp\n",
    "Original LTC repo :https://github.com/raminmh/liquid_time_constant_networks\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerasncp import wirings\n",
    "from kerasncp.tf import LTCCell\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory here if needed\n",
    "traffic_data = pandas.read_csv('/Users/adrianchoi/Desktop/760/ncp-time-series/data/Metro_Interstate_Traffic_Volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame.info(traffic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame.describe(traffic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = (traffic_data[\"holiday\"].values == None).astype(np.float32)\n",
    "temp = traffic_data[\"temp\"].values.astype(np.float32)\n",
    "temp -= np.mean(temp) #normalize temp by annual mean\n",
    "rain = traffic_data[\"rain_1h\"].values.astype(np.float32)\n",
    "snow = traffic_data[\"snow_1h\"].values.astype(np.float32)\n",
    "clouds = traffic_data[\"clouds_all\"].values.astype(np.float32)\n",
    "date_time = traffic_data[\"date_time\"].values\n",
    "    #2012-10-02 13:00:00\n",
    "date_time = [datetime.datetime.strptime(d,\"%Y-%m-%d %H:%M:%S\") for d in date_time]\n",
    "weekday = np.array([d.weekday() for d in date_time]).astype(np.float32)\n",
    "noon = np.array([d.hour for d in date_time]).astype(np.float32)\n",
    "noon = np.sin(noon*np.pi/24)\n",
    "\n",
    "features = np.stack([holiday,temp,rain,snow,clouds,weekday,noon],axis=-1)\n",
    "\n",
    "traffic_volume = traffic_data[\"traffic_volume\"].values.astype(np.float32)\n",
    "traffic_volume -= np.mean(traffic_volume) #normalize\n",
    "traffic_volume /= np.std(traffic_volume) #normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf of traffic-volume\n",
    "pandas.Series(traffic_volume).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"preprocessed_traffic_data.csv\", features, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory here if needed\n",
    "preprocessed_traffic_data = pandas.read_csv('/Users/adrianchoi/Desktop/760/ncp-time-series/preprocessed_traffic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame.describe(preprocessed_traffic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_in_sequences(x,y,seq_len,inc=1):\n",
    "\n",
    "    sequences_x = []\n",
    "    sequences_y = []\n",
    "\n",
    "    for s in range(0,x.shape[0] - seq_len,inc):\n",
    "        start = s\n",
    "        end = start+seq_len\n",
    "        sequences_x.append(x[start:end])\n",
    "        sequences_y.append(y[start:end])\n",
    "\n",
    "    return np.stack(sequences_x,axis=1),np.stack(sequences_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "train_x,train_y = cut_in_sequences(features,traffic_volume,32,inc=4)\n",
    "train_x = np.stack(train_x,axis=1)\n",
    "train_y = np.stack(train_y,axis=1)\n",
    "\n",
    "total_seqs = train_x.shape[1]\n",
    "print(\"Total number of training sequences: {}\".format(total_seqs))\n",
    "permutation = np.random.RandomState(23489).permutation(total_seqs)\n",
    "valid_size = int(0.1*total_seqs)\n",
    "test_size = int(0.15*total_seqs)\n",
    "valid_x = train_x[:,permutation[:valid_size]]\n",
    "valid_y = train_y[:,permutation[:valid_size]]\n",
    "test_x = train_x[:,permutation[valid_size:valid_size+test_size]]\n",
    "test_y = train_y[:,permutation[valid_size:valid_size+test_size]]\n",
    "train_x = train_x[:,permutation[valid_size+test_size:]]\n",
    "train_y = train_y[:,permutation[valid_size+test_size:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the data in a sequence of length 32\n",
    "train_x,train_y = cut_in_sequences(features,traffic_volume,32,inc=4)\n",
    "train_x = np.stack(train_x,axis=1)\n",
    "train_y = np.stack(train_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [3,6,8,10,12,14,16]\n",
    "\n",
    "# higher sparsity is likely to cause overfitting\n",
    "sparsity = [0.1,0.2,0.3,0.6,0.8]\n",
    "\n",
    "# epochs\n",
    "epochs_n = 20\n",
    "\n",
    "# batch size\n",
    "batch_size_n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with hyparameters - number of neurons, sparsity\n",
    "for i in neurons:\n",
    "    for j in sparsity: \n",
    "        arch = kerasncp.wirings.Random(i, 1, sparsity_level=j)\n",
    "        rnn_cell = LTCCell(arch)\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.Input((None, 7)),\n",
    "                tf.keras.layers.RNN(rnn_cell, return_sequences=True),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(0.01,epsilon=1e-08), loss=tf.keras.losses.MeanSquaredError()\n",
    "        )\n",
    "\n",
    "        traffic_ncp_history = model.fit(x=train_x, y=train_y, batch_size=batch_size_n, epochs=epochs_n, validation_data=(valid_x,valid_y))\n",
    "        \n",
    "        loss_train = traffic_ncp_history.history['loss']\n",
    "        loss_val = traffic_ncp_history.history['val_loss']\n",
    "        epochs = range(1,epochs_n+1)\n",
    "        plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "        plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "        plt.title('Training and Validation MSE loss ')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
